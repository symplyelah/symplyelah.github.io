{
  "hash": "ec5f0eee631cbaa875b216e74bc7f7e3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Topic Modeling: Turning Conversations into Strategy\"\nsubtitle: \"R Ladies Abuja\"\nauthor: Ifeoma Egbogah\nformat: \n  rladies-revealjs\nincremental: false\nembed-resources: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n# The Rise of Unstructured Data {.inverse}\n\n## From Numbers to Words\n\n<div style = \"font-size:0.85em;\">\nIf you're in the field of analytics or data science, you're likely well aware that data is being produced continuously—and at an increasingly rapid pace. (You might even be tired of hearing this repeated!) While analysts are typically trained to work with structured, numeric data in table formats, a significant portion of today’s data boom involves unstructured, text-based information.\n\n>Unstructured data represents 80-90% of all new enterprise data, according to Gartner.\n\nFurthermore, it’s growing three times faster than structured data. \n\n</div>\n\n# Behind the Words {.inverse}\n## Overview\n\nIn this webinar, we will look at:\n\n* Understanding Topic Modeling\n* Importance of Topi Modeling\n* Topic Modeling Techniques\n* Implementation of Topic Modeling\n* Demo\n\n# Understanding Topic Modeling {.inverse}\n## What is Topic Modeling?\n\n<div style = \"font-size:0.85em;\">\nTopic modeling is way to identify themes/semantic patterns in a corpus (complete document).\n\nTopic modeling finds the relationships between words in the text, thereby identifying clusters of words that represent topics. \n\nIt is a like an amplified reading, a way to discover themes you may not see yourself.\n\n### Glossary:\n\n*Corpus:* Group of documents\n*Documents:* Newspaper, Blogpost, Tweets, Articles, Journals, Customer reviews etc.\n</div>\n\n# Importance of Topic Modeling {.inverse}\n##\n\n# Topic Modeling Techniques {.inverse}\n## Latent Dirichlet Allocation (LDA)\n\n:::: columns\n::: {.column width=100%}\n\n<div style=\"text-align: center;\">\n![](./images/lda.png){width=\"90%\"}\n <p style=\"font-size:0.35em;\">Source: Introduction to Probabilistic Topic Models paper by Blei et. al</p>\n</div>\n\n:::\n::::\n\n<div style = \"font-size:0.70em;\">\nLatent Dirichlet allocation is one of the most common algorithms for topic modeling. It is guided by two principles, that:\n\n* Every document is a mixture of topics\n* Every topic is a mixture of words\n</div>\n\n# Implementation of Topic Modeling {.inverse}\n## Step 1\n### Data  Preparation\n<div style = \"font-size:0.85em;\">\nCollect the text data\n</div>\n\n## Step 2\n### Preprocessing\n<div style = \"font-size:0.85em;\">\nBefore modeling, we preprocess the data to put in it in a tidy format by:\n\n* Tokenization (splitting sentences into words)\n\n* Removing punctuation, numbers \n\n* Removing stop words (like the, and, is)\n\n* Find document-word counts\n</div>\n\n## Step 3\n### Create Document-term Matrix\n\n<div style = \"font-size:0.85em;\">\nA matrix that represents the frequency of each word (term) across all documents.\n\nWe can cast a one-token-per-row table into a `DocumentTermMatrix` with tidytext’s `cast_dtm()`.\n\n*Rows = documents; Columns = terms/words.*\n\n</div>\n\n## Step 4\n### Model Fitting\n\n<div style = \"font-size:0.85em;\">\nWe can then use the `LDA()` function from the `topicmodels` package to create a topic model.\n</div>\n\n## Step 5\n### Interprete and Visualise the Result\n\n<div style = \"font-size:0.85em;\">\n* Extract top keywords per topic.\n\n* Label the topics manually (e.g., “Customer Service Issues” or “Product Features”).\n\n* Visualize using `tools like: `ggplot2` package\n\n</div>\n\n## Step 6\n### Apply Result\n\n<div style = \"font-size:0.85em;\">\nSummarize the result, identify customer pain points, track emerging trends etc\n\n</div>\n\n# Packages {.inverse}\n\n## Packages\n<div style = \"font-size:0.85em;\">\nWe will make use of the following packages\n\n`tidyverse`\n`tidytext`\n`topicmodels`\n`tm`\n\n</div>\n\n\n\n# Demo {.inverse}\n\n\n\n::: {.cell}\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}